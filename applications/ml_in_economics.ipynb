{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fea6435",
   "metadata": {},
   "source": [
    "# Machine Learning in Economics\n",
    "\n",
    "**Author**\n",
    "\n",
    "> - [Paul Schrimpf *UBC*](https://economics.ubc.ca/faculty-and-staff/paul-schrimpf/)  \n",
    "\n",
    "\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- [Regression](https://datascience.quantecon.org/../tools/regression.html)  \n",
    "\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand how economists use machine learning in\n",
    "  academic research  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807eaed2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Uncomment following line to install on colab\n",
    "#! pip install fiona geopandas xgboost gensim folium pyLDAvis descartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb66ca73",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.style.use('tableau-colorblind10')\n",
    "#plt.style.use('Solarize_Light2')\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb1180",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Machine learning is increasingly being utilized in economic\n",
    "research. Here, we discuss three main ways that economists are\n",
    "currently using machine learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826d5a55",
   "metadata": {},
   "source": [
    "## Prediction Policy\n",
    "\n",
    "Most empirical economic research focuses on questions of\n",
    "causality. However, machine learning methods can actually be used\n",
    "in economic research or policy making when the goal is prediction.\n",
    "\n",
    "[[mlKLMO15](#id13)] is a short paper which makes this point.\n",
    "\n",
    "> Consider two toy examples. One policymaker facing a drought must\n",
    "decide whether to invest in a rain dance to increase the chance\n",
    "of rain.  Another seeing clouds must decide whether to take an\n",
    "umbrella to work to avoid getting wet on the way home. Both\n",
    "decisions could benefit from an empirical study of rain. But each\n",
    "has differ-ent requirements of the estimator. One requires\n",
    "causality: Do rain dances cause rain? The other does not, needing\n",
    "only prediction: Is the chance of rain high enough to merit an\n",
    "umbrella?  We often focus on rain dance–like policy problems. But\n",
    "there are also many umbrella-like policy problems.  Not only are\n",
    "these prediction problems neglected, machine learning can help\n",
    "us solve them more effectively.  [[mlKLMO15](#id13)].\n",
    "\n",
    "\n",
    "One of their examples is the allocation of joint replacements for\n",
    "osteoarthritis in elderly patients. Joint replacements are costly,\n",
    "both monetarily and in terms of potentially painful recovery from\n",
    "surgery. Joint replacements may not be worthwhile for patients who do\n",
    "not live long enough afterward to enjoy the\n",
    "benefits. [[mlKLMO15](#id13)] uses machine learning methods to\n",
    "predict mortality and argues that avoiding joint replacements\n",
    "for people with the highest predicted mortality risk could lead to\n",
    "sizable benefits.\n",
    "\n",
    "Other situations where improved prediction could improve economic\n",
    "policy include:\n",
    "\n",
    "- Targeting safety or health inspections.  \n",
    "- Predicting highest risk youth for targeting interventions.  \n",
    "- Improved risk scoring in insurance markets to reduce adverse\n",
    "  selection.  \n",
    "- Improved credit scoring to better allocate credit.  \n",
    "- Predicting the risk someone accused of a crime does not show up for\n",
    "  trial to help decide whether to offer bail [[mlKLL+17](#id12)].  \n",
    "\n",
    "\n",
    "We investigated one such prediction policy problem in\n",
    "[recidivism](https://datascience.quantecon.org/recidivism.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0000d8",
   "metadata": {},
   "source": [
    "## Estimation of Nuisance Functions\n",
    "\n",
    "Most empirical economic studies are interested in a single low\n",
    "dimensional parameter, but determining that parameter may require estimating additional\n",
    "“nuisance” parameters to estimate this coefficient consistently and avoid omitted variables\n",
    "bias. However, the choice of which other variables to include and\n",
    "their functional forms is often somewhat arbitrary.\n",
    "One promising idea is to use machine learning methods to let the data\n",
    "decide what control variables to include and how. Care must be\n",
    "taken when doing so, though, because machine learning’s flexibility and complexity\n",
    "– what make it so good at prediction – also pose\n",
    "challenges for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d4970f",
   "metadata": {},
   "source": [
    "### Partially Linear Regression\n",
    "\n",
    "To be more concrete, consider a regression model.  We have some\n",
    "regressor of interest, $ d $, and we want to estimate the effect of $ d $\n",
    "on $ y $. We have a rich enough set of controls $ x $ that we are willing to\n",
    "believe that $ E[\\epsilon|d,x] = 0 $ . $ d_i $ and $ y_i $ are scalars, while\n",
    "$ x_i $ is a vector. We are not interested in $ x $ per se, but we need to\n",
    "include it to avoid omitted variable bias. Suppose the true model\n",
    "generating the data is:\n",
    "\n",
    "$$\n",
    "y = \\theta d + f(x) + \\epsilon\n",
    "$$\n",
    "\n",
    "where $ f(x) $ is some unknown function. This is called a\n",
    "partially linear model: linear in $ d $, but not in\n",
    "$ x $ .\n",
    "\n",
    "A typical applied econometric approach for this model would\n",
    "be to choose some transform of $ x $, say $ X = T(x) $, where $ X $\n",
    "could be some subset of $ x $ , perhaps along with interactions, powers, and\n",
    "so on. Then, we estimate a linear regression,\n",
    "\n",
    "$$\n",
    "y = \\theta d + X'\\beta + e\n",
    "$$\n",
    "\n",
    "and then perhaps also report results for a handful of different\n",
    "choices of $ T(x) $ .\n",
    "\n",
    "Some downsides to the typical applied econometric practice\n",
    "include:\n",
    "\n",
    "- The choice of $ T $ is arbitrary, which opens the door to specification\n",
    "  searching and p-hacking.  \n",
    "- If $ x $ is high dimensional and $ X $ is low dimensional, a poor\n",
    "  choice will lead to omitted variable bias. Even if $ x $ is low\n",
    "  dimensional,  omitted variable bias occurs if $ f(x) $ is poorly approximated by $ X'\\beta $.  \n",
    "\n",
    "\n",
    "In some sense, machine learning can be thought of as a way to\n",
    "choose $ T $ in an automated and data-driven way. Choosing which machine learning method\n",
    "to use and tuning parameters specifically for that method are still potentially arbitrary\n",
    "decisions, but these decisions may have less impact.\n",
    "\n",
    "Economic researchers typically don’t just want an estimate of\n",
    "$ \\theta $, $ \\hat{\\theta} $. Instead, they want to know that\n",
    "$ \\hat{\\theta} $ has good statistical properties (it should at\n",
    "least be consistent), and they want some way to quantify how uncertain is\n",
    "$ \\hat{\\theta} $ (i.e. they want a standard error). The complexity\n",
    "of machine learning methods makes their statistical properties\n",
    "difficult to understand. If we want $ \\hat{\\theta} $ to have\n",
    "known and good statistical properties, we must make sure we use machine\n",
    "learning methods correctly.  A procedure to estimate\n",
    "$ \\theta $ in the partially linear model is as follows:\n",
    "\n",
    "1. Predict $ y $ and $ d $ from $ x $ using any machine\n",
    "  learning method with “cross-fitting”.  \n",
    "  - Partition the data in $ k $ subsets.  \n",
    "  - For the $ j $ th subset, train models to predict $ y $ and $ d $\n",
    "    using the other $ k-1 $ subsets. Denote the predictions from\n",
    "    these models as $ p^y_{-j}(x) $ and  $ p^d_{-j}(x) $.  \n",
    "  - For $ y_i $ in the $ j $ -th subset use the other\n",
    "    $ k-1 $ subsets to predict $ \\hat{y}_i = p^y_{-j(i)}(x_i) $  \n",
    "1. Partial out $ x $ : let $ \\tilde{y}_i = y_i - \\hat{y}_i $\n",
    "  and $ \\tilde{d}_i = d_i - \\hat{d}_i $.  \n",
    "1. Regress $ \\tilde{y}_i $ on $ \\tilde{d}_i $, let\n",
    "  $ \\hat{\\theta} $ be the estimated coefficient for\n",
    "  $ \\tilde{d}_i $ . $ \\hat{\\theta} $ is consistent,\n",
    "  asymptotically normal, and has the usual standard error (i.e. the\n",
    "  standard error given by statsmodels is correct).  \n",
    "\n",
    "\n",
    "Some remarks:\n",
    "\n",
    "- This procedure gives a $ \\hat{\\theta} $ that has the same\n",
    "  asymptotic distribution as what we would get if we knew the true\n",
    "  $ f(x) $ . In statistics, we call this an oracle property,\n",
    "  because it is as if an all knowing oracle told us $ f(x) $.  \n",
    "- This procedure requires some technical conditions on the data-generating\n",
    "  process and machine learning estimator, but we will not worry about them here. See\n",
    "  [[mlCCD+18](#id14)] for details.  \n",
    "\n",
    "\n",
    "Here is code implementing the above idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1202b4fd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "import statsmodels as sm\n",
    "\n",
    "def partial_linear(y, d, X, yestimator, destimator, folds=3):\n",
    "    \"\"\"Estimate the partially linear model y = d*C + f(x) + e\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "        vector of outcomes\n",
    "    d : array_like\n",
    "        vector or matrix of regressors of interest\n",
    "    X : array_like\n",
    "        matrix of controls\n",
    "    mlestimate : Estimator object for partialling out X. Must have ‘fit’\n",
    "        and ‘predict’ methods.\n",
    "    folds : int\n",
    "        Number of folds for cross-fitting\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ols : statsmodels regression results containing estimate of coefficient on d.\n",
    "    yhat : cross-fitted predictions of y\n",
    "    dhat : cross-fitted predictions of d\n",
    "    \"\"\"\n",
    "\n",
    "    # we want predicted probabilities if y or d is discrete\n",
    "    ymethod = \"predict\" if False==getattr(yestimator, \"predict_proba\",False) else \"predict_proba\"\n",
    "    dmethod = \"predict\" if False==getattr(destimator, \"predict_proba\",False) else \"predict_proba\"\n",
    "    # get the predictions\n",
    "    yhat = cross_val_predict(yestimator,X,y,cv=folds,method=ymethod)\n",
    "    dhat = cross_val_predict(destimator,X,d,cv=folds,method=dmethod)\n",
    "    ey = np.array(y - yhat)\n",
    "    ed = np.array(d - dhat)\n",
    "    ols = sm.regression.linear_model.OLS(ey,ed).fit(cov_type='HC0')\n",
    "\n",
    "    return(ols, yhat, dhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a518c95",
   "metadata": {},
   "source": [
    "### Application: Gender Wage Gap\n",
    "\n",
    "Okay, enough theory. Let’s look at an application. Policy makers have\n",
    "long been concerned with the gender wage gap. We will examine the\n",
    "gender wage gap using data from the 2018 Current Population Survey (CPS) in\n",
    "the US. In particular, we will use the version of the [CPS provided by\n",
    "the NBER](https://www.nber.org/cps/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27ac15e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\http\\client.py:1298\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\http\\client.py:1344\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1343\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\http\\client.py:1293\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\http\\client.py:1052\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m \n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\http\\client.py:990\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 990\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\http\\client.py:1463\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1463\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\http\\client.py:956\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    955\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m--> 956\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(\n\u001b[0;32m    957\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address)\n\u001b[0;32m    958\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\socket.py:827\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    826\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m getaddrinfo(host, port, \u001b[38;5;241m0\u001b[39m, SOCK_STREAM):\n\u001b[0;32m    828\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miolib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary_col\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Download CPS data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m cpsall \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.nber.org/morg/annual/morg18.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# take subset of data just to reduce computation time\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cps \u001b[38;5;241m=\u001b[39m cpsall\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m30000\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:2109\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[1;32m-> 2109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1683\u001b[0m, in \u001b[0;36mStataReader.read\u001b[1;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m   1673\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1681\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1682\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 1683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_open()\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# Handle options\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1175\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_file()\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1188\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered:\n\u001b[0;32m   1182\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStataReader is being used without using a context manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing StataReader as a context manager is the only supported method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;167;01mResourceWarning\u001b[39;00m,\n\u001b[0;32m   1186\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1187\u001b[0m     )\n\u001b[1;32m-> 1188\u001b[0m handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_path_or_buf,\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1191\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_options,\n\u001b[0;32m   1192\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1193\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression,\n\u001b[0;32m   1194\u001b[0m )\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;66;03m# If the handle is directly seekable, use it without an extra copy.\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    729\u001b[0m     path_or_buf,\n\u001b[0;32m    730\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    731\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    732\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    733\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\chadi\\anaconda3\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "# Download CPS data\n",
    "cpsall = pd.read_stata(\"https://www.nber.org/morg/annual/morg18.dta\")\n",
    "\n",
    "# take subset of data just to reduce computation time\n",
    "cps = cpsall.sample(30000, replace=False, random_state=0)\n",
    "display(cps.head())\n",
    "cps.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9d8d2",
   "metadata": {},
   "source": [
    "The variable “earnwke” records weekly earnings. Two\n",
    "variables detail the hours of work. “uhours” is usual hours worked per\n",
    "week, and “hourslw” is hours worked last week. We will try using each\n",
    "measure of hours to construct the wage.  Let’s estimate the\n",
    "unconditional gender earnings and wage gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cafb5c4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (cps\u001b[38;5;241m.\u001b[39msex\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m cps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_earn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(cps\u001b[38;5;241m.\u001b[39mearnwke)\n\u001b[0;32m      3\u001b[0m cps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_earn\u001b[39m\u001b[38;5;124m\"\u001b[39m][np\u001b[38;5;241m.\u001b[39misinf(cps\u001b[38;5;241m.\u001b[39mlog_earn)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cps' is not defined"
     ]
    }
   ],
   "source": [
    "cps[\"female\"] = (cps.sex==2)\n",
    "cps[\"log_earn\"] = np.log(cps.earnwke)\n",
    "cps[\"log_earn\"][np.isinf(cps.log_earn)] = np.nan\n",
    "cps[\"log_uhours\"] = np.log(cps.uhourse)\n",
    "cps[\"log_uhours\"][np.isinf(cps.log_uhours)] = np.nan\n",
    "cps[\"log_hourslw\"] = np.log(cps.hourslw)\n",
    "cps[\"log_hourslw\"][np.isinf(cps.log_hourslw)] = np.nan\n",
    "cps[\"log_wageu\"] = cps.log_earn - cps.log_uhours\n",
    "cps[\"log_wagelw\"] = cps.log_earn - cps.log_hourslw\n",
    "\n",
    "\n",
    "lm = list()\n",
    "lm.append(smf.ols(formula=\"log_earn ~ female\", data=cps,\n",
    "                  missing=\"drop\").fit(cov_type='HC0'))\n",
    "lm.append( smf.ols(formula=\"log_wageu ~ female\", data=cps,\n",
    "                   missing=\"drop\").fit(cov_type='HC0'))\n",
    "lm.append(smf.ols(formula=\"log_wagelw ~ female\", data=cps,\n",
    "                  missing=\"drop\").fit(cov_type='HC0'))\n",
    "lm.append(smf.ols(formula=\"log_earn ~ female + log_hourslw + log_uhours\", data=cps,\n",
    "                  missing=\"drop\").fit(cov_type='HC0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce512587",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summary_col(lm, stars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "summary_col(lm, stars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867de48",
   "metadata": {},
   "source": [
    "The unconditional gender gap in log earnings is about -0.3. Women earn\n",
    "about 30% less than men. The unconditional gender wage gap is about\n",
    "18%. The last column gives the gender earnings gap conditional on\n",
    "hours. This could differ from the wage gap if, for example, full time\n",
    "workers are paid higher wages than part-time. Some evidence\n",
    "has suggested this, and the gender earnings gap conditional on hours is about\n",
    "15%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a721a07",
   "metadata": {},
   "source": [
    "#### Equal Pay for Equal Work?\n",
    "\n",
    "A common slogan is equal pay for equal work. One way to interpret this\n",
    "is that for employees with similar worker and job characteristics, no gender wage gap should exist.\n",
    "\n",
    "Eliminating this wage gap across similar worker and job characteristics is one necessary\n",
    "(though insufficient) condition for equality. Some of the differences (like hours in the 4th column of the above table)\n",
    "might actually be a result of societal norms and/or\n",
    "discrimination, so we don’t want to overgeneralize.\n",
    "\n",
    "Nonetheless, let’s examine whether there is a gender wage gap\n",
    "conditional on all worker and job characteristics. We want to ensure\n",
    "that we control for those characteristics as flexibly as\n",
    "possible, so we will use the partially linear model described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288d2d97",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m fmla  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_earn + female ~ log_uhours + log_hourslw + age + I(age**2) + C(race) + C(cbsafips) + C(smsastat) + C(grade92) + C(unionmme) + C(unioncov) + C(ind02) + C(occ2012)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m yd, X \u001b[38;5;241m=\u001b[39m dmatrices(fmla,cps)\n\u001b[0;32m      5\u001b[0m female \u001b[38;5;241m=\u001b[39m yd[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      6\u001b[0m logearn \u001b[38;5;241m=\u001b[39m yd[:,\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cps' is not defined"
     ]
    }
   ],
   "source": [
    "from patsy import dmatrices\n",
    "# Prepare data\n",
    "fmla  = \"log_earn + female ~ log_uhours + log_hourslw + age + I(age**2) + C(race) + C(cbsafips) + C(smsastat) + C(grade92) + C(unionmme) + C(unioncov) + C(ind02) + C(occ2012)\"\n",
    "yd, X = dmatrices(fmla,cps)\n",
    "female = yd[:,1]\n",
    "logearn = yd[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1cae8c",
   "metadata": {},
   "source": [
    "The choice of regularization parameter is somewhat\n",
    "tricky. Cross-validation is a good way to choose the best\n",
    "regularization parameter when our goal is prediction. However,\n",
    "our goal here is not prediction. Instead, we want to get a well-behaved\n",
    "estimate of the gender wage gap. To achieve this, we generally need a\n",
    "smaller regularization parameter than what would minimize\n",
    "MSE. The following code picks such a regularization parameter. Note\n",
    "however, that the details of this code might not meet the technical\n",
    "theoretical conditions needed for our ultimate estimate of the gender\n",
    "wage gap to be consistent and asymptotically normal. The R package,\n",
    "“HDM” [[mlCHS16](#id21)] , chooses the regularization parameter in way that\n",
    "is known to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721e59b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# select regularization parameter\n",
    "alphas = np.exp(np.linspace(-2, -12, 25))\n",
    "lassoy = linear_model.LassoCV(cv=6, alphas=alphas, max_iter=5000).fit(X,logearn)\n",
    "lassod = linear_model.LassoCV(cv=6, alphas=alphas, max_iter=5000).fit(X,female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0856c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "def plotlassocv(l, ax) :\n",
    "    alphas = l.alphas_\n",
    "    mse = l.mse_path_.mean(axis=1)\n",
    "    std_error = l.mse_path_.std(axis=1)\n",
    "    ax.plot(alphas,mse)\n",
    "    ax.fill_between(alphas, mse + std_error, mse - std_error, alpha=0.2)\n",
    "\n",
    "    ax.set_ylabel('MSE +/- std error')\n",
    "    ax.set_xlabel('alpha')\n",
    "    ax.set_xlim([alphas[0], alphas[-1]])\n",
    "    ax.set_xscale(\"log\")\n",
    "    return(ax)\n",
    "\n",
    "ax[0] = plotlassocv(lassoy,ax[0])\n",
    "ax[0].set_title(\"MSE for log(earn)\")\n",
    "ax[1] = plotlassocv(lassod,ax[1])\n",
    "ax[1].set_title(\"MSE for female\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# there are theoretical reasons to choose a smaller regularization\n",
    "# than the one that minimizes cv. BUT THIS WAY OF CHOOSING IS ARBITRARY AND MIGHT BE WRONG\n",
    "def pickalpha(lassocv) :\n",
    "    imin = np.argmin(lassocv.mse_path_.mean(axis=1))\n",
    "    msemin = lassocv.mse_path_.mean(axis=1)[imin]\n",
    "    se = lassocv.mse_path_.std(axis=1)[imin]\n",
    "    alpha= min([alpha for (alpha, mse) in zip(lassocv.alphas_, lassocv.mse_path_.mean(axis=1)) if mse<msemin+se])\n",
    "    return(alpha)\n",
    "\n",
    "alphay = pickalpha(lassoy)\n",
    "alphad = pickalpha(lassod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aee7a1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# show results\n",
    "pl_lasso = partial_linear(logearn, female, X,\n",
    "                          linear_model.Lasso(alpha=lassoy.alpha_),\n",
    "                          linear_model.Lasso(alpha=lassod.alpha_))\n",
    "pl_lasso[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736933a8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Visualize predictions\n",
    "def plotpredictions(pl) :\n",
    "    df = pd.DataFrame({\"logearn\":logearn,\n",
    "                       \"predicted\":pl[1],\n",
    "                       \"female\":female,\n",
    "                       \"P(female|x)\":pl[2]})\n",
    "    sns.pairplot(df, vars=[\"logearn\",\"predicted\"], hue=\"female\")\n",
    "    plt.title(\"Observed and predicted log(earnings)\")\n",
    "\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x = df.predicted, y = df.logearn-df.predicted, hue=df.female)\n",
    "    plt.title(\"Prediction Errors\")\n",
    "\n",
    "    plt.figure()\n",
    "    sns.distplot(pl[2][female==0], hist = True, kde = False,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3},\n",
    "                 label = \"Male\")\n",
    "    sns.distplot(pl[2][female==1], hist = True, kde = False,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3},\n",
    "                 label = \"Female\")\n",
    "    plt.title('P(female|x)')\n",
    "plotpredictions(pl_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b491a3a",
   "metadata": {},
   "source": [
    "We see that the gender earnings gap is\n",
    "12.4%, conditional on hours, age, race, location, education,\n",
    "union membership, industry, and occupation.\n",
    "Compared to the gap conditional on only hours, differences in other observable characteristics in the CPS seem unable explain much of the gender earnings gap.\n",
    "\n",
    "We can repeat the same procedure with another machine learning method\n",
    "in place of lasso. Let’s try it with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd02cde",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "from sklearn import preprocessing, pipeline, model_selection\n",
    "\n",
    "nnp = pipeline.Pipeline(steps=[\n",
    "    (\"scaling\", preprocessing.StandardScaler()),\n",
    "    (\"nn\", neural_network.MLPRegressor((50,), activation=\"logistic\",\n",
    "                                       verbose=False, solver=\"adam\",\n",
    "                                       max_iter=400, early_stopping=True,\n",
    "                                       validation_fraction=0.15))\n",
    "])\n",
    "\n",
    "nndcv = model_selection.GridSearchCV(estimator=nnp, scoring= 'neg_mean_squared_error', cv=4,\n",
    "                                     param_grid = {'nn__alpha': np.exp(np.linspace(-5,5, 10))},\n",
    "                                     return_train_score=True, verbose=True, refit=False,\n",
    "                                     ).fit(X,female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff8080",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "nnycv = model_selection.GridSearchCV(estimator=nnp, scoring= 'neg_mean_squared_error', cv=4,\n",
    "                                     param_grid = {'nn__alpha': np.exp(np.linspace(-5,5, 10))},\n",
    "                                     return_train_score=True, verbose=True, refit=False,\n",
    "                                     ).fit(X,logearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62cff7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "def plotgridcv(g, ax) :\n",
    "    alphas = g.cv_results_[\"param_nn__alpha\"].data.astype(float)\n",
    "    mse = -g.cv_results_[\"mean_test_score\"]\n",
    "    std_error = g.cv_results_[\"std_test_score\"]\n",
    "    ax.plot(alphas,mse)\n",
    "    ax.fill_between(alphas, mse+std_error, mse-std_error, alpha=0.2)\n",
    "\n",
    "    ax.set_ylabel('MSE +/- std error')\n",
    "    ax.set_xlabel('alpha')\n",
    "    ax.set_xlim([alphas[0], alphas[-1]])\n",
    "    ax.set_xscale(\"log\")\n",
    "    return(ax)\n",
    "\n",
    "ax[0] = plotgridcv(nnycv,ax[0])\n",
    "ax[0].set_title(\"MSE for log(earn)\")\n",
    "ax[1] = plotgridcv(nndcv,ax[1])\n",
    "ax[1].set_title(\"MSE for female\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# there are theoretical reasons to choose a smaller regularization\n",
    "# than the one that minimizes cv. BUT THIS WAY OF CHOOSING IS ARBITRARY AND MAYBE WRONG\n",
    "def pickalphagridcv(g) :\n",
    "    alphas = g.cv_results_[\"param_nn__alpha\"].data\n",
    "    mses = g.cv_results_[\"mean_test_score\"]\n",
    "    imin = np.argmin(mses)\n",
    "    msemin = mses[imin]\n",
    "    se = g.cv_results_[\"std_test_score\"][imin]\n",
    "    alpha= min([alpha for (alpha, mse) in zip(alphas, mses) if mse<msemin+se])\n",
    "    return(alpha)\n",
    "\n",
    "alphaynn = pickalphagridcv(nnycv)\n",
    "alphadnn = pickalphagridcv(nndcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d34a2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# show results\n",
    "nny = nnp\n",
    "nny.set_params(nn__alpha = alphaynn)\n",
    "nnd = nnp\n",
    "nnd.set_params(nn__alpha = alphadnn)\n",
    "pl_nn = partial_linear(logearn, female, X,\n",
    "                       nny, nnd)\n",
    "pl_nn[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a9f30",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plotpredictions(pl_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f83399",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "summary_col([pl_lasso[0], pl_nn[0]], model_names=[\"Lasso\", \"Neural Network\"] ,stars=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3ac8f",
   "metadata": {},
   "source": [
    "### Other Applications\n",
    "\n",
    "Machine learning can be used to\n",
    "estimate nuisance functions in many other situations. The partially linear model can easily be\n",
    "extended to situations where the regressor of interest, $ d $ , is\n",
    "endogenous and instruments are available. See [[mlCCD+18](#id14)]\n",
    "for details and additional examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5689294f",
   "metadata": {},
   "source": [
    "## Heterogeneous Effects\n",
    "\n",
    "A third area where economists are using machine learning is to\n",
    "estimate heterogeneous effects.\n",
    "\n",
    "Some important papers in this area are [[mlAI16](#id18)] ,\n",
    "[[mlWA18](#id17)] , and [[mlCDDFV18](#id16)] .\n",
    "\n",
    "We will explore this is more depth in [heterogeneity](https://datascience.quantecon.org/heterogeneity.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff589da0",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id='id18'></a>\n",
    "\\[mlAI16\\] Susan Athey and Guido Imbens. Recursive partitioning for heterogeneous causal effects. *Proceedings of the National Academy of Sciences*, 113(27):7353–7360, 2016. URL: [http://www.pnas.org/content/113/27/7353](http://www.pnas.org/content/113/27/7353), [arXiv:http://www.pnas.org/content/113/27/7353.full.pdf](https://arxiv.org/abs/http://www.pnas.org/content/113/27/7353.full.pdf), [doi:10.1073/pnas.1510489113](https://doi.org/10.1073/pnas.1510489113).\n",
    "\n",
    "<a id='id14'></a>\n",
    "\\[mlCCD+18\\] Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. Double/debiased machine learning for treatment and structural parameters. *The Econometrics Journal*, 21(1):C1–C68, 2018. URL: [https://onlinelibrary.wiley.com/doi/abs/10.1111/ectj.12097](https://onlinelibrary.wiley.com/doi/abs/10.1111/ectj.12097), [arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097](https://arxiv.org/abs/https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097), [doi:10.1111/ectj.12097](https://doi.org/10.1111/ectj.12097).\n",
    "\n",
    "<a id='id16'></a>\n",
    "\\[mlCDDFV18\\] Victor Chernozhukov, Mert Demirer, Esther Duflo, and Iván Fernández-Val. Generic machine learning inference on heterogenous treatment effects in randomized experimentsxo. Working Paper 24678, National Bureau of Economic Research, June 2018. URL: [http://www.nber.org/papers/w24678](http://www.nber.org/papers/w24678), [doi:10.3386/w24678](https://doi.org/10.3386/w24678).\n",
    "\n",
    "<a id='id21'></a>\n",
    "\\[mlCHS16\\] Victor Chernozhukov, Chris Hansen, and Martin Spindler. hdm: high-dimensional metrics. *R Journal*, 8(2):185–199, 2016. URL: [https://journal.r-project.org/archive/2016/RJ-2016-040/index.html](https://journal.r-project.org/archive/2016/RJ-2016-040/index.html).\n",
    "\n",
    "<a id='id12'></a>\n",
    "\\[mlKLL+17\\] Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. Human Decisions and Machine Predictions*. *The Quarterly Journal of Economics*, 133(1):237–293, 08 2017. URL: [https://dx.doi.org/10.1093/qje/qjx032](https://dx.doi.org/10.1093/qje/qjx032), [arXiv:http://oup.prod.sis.lan/qje/article-pdf/133/1/237/24246094/qjx032.pdf](https://arxiv.org/abs/http://oup.prod.sis.lan/qje/article-pdf/133/1/237/24246094/qjx032.pdf), [doi:10.1093/qje/qjx032](https://doi.org/10.1093/qje/qjx032).\n",
    "\n",
    "<a id='id13'></a>\n",
    "\\[mlKLMO15\\] Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. Prediction policy problems. *American Economic Review*, 105(5):491–95, May 2015. URL: [http://www.aeaweb.org/articles?id=10.1257/aer.p20151023](http://www.aeaweb.org/articles?id=10.1257/aer.p20151023), [doi:10.1257/aer.p20151023](https://doi.org/10.1257/aer.p20151023).\n",
    "\n",
    "<a id='id17'></a>\n",
    "\\[mlWA18\\] Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using random forests. *Journal of the American Statistical Association*, 0(0):1–15, 2018. URL: [https://doi.org/10.1080/01621459.2017.1319839](https://doi.org/10.1080/01621459.2017.1319839), [arXiv:https://doi.org/10.1080/01621459.2017.1319839](https://arxiv.org/abs/https://doi.org/10.1080/01621459.2017.1319839), [doi:10.1080/01621459.2017.1319839](https://doi.org/10.1080/01621459.2017.1319839)."
   ]
  }
 ],
 "metadata": {
  "date": 1712969536.9255028,
  "filename": "ml_in_economics.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "title": "Machine Learning in Economics"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
